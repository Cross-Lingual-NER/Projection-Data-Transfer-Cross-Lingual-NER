# @package _global_

pipeline:
  open_orig:
    deps: []
    transform:
      _target_: src.pipelines.data.LoadHFDataset
      cfg_name: null
      split: test
      label2id_save_path: label2id.json
  detokenize:
    deps: [open_orig]
    transform:
      _target_: src.pipelines.word_splitting.DetokenizeTransform
  fwd_translation:
    deps: [detokenize]
    transform:
      _target_: src.pipelines.translation.FairseqTranslationTransform
      model_path: ???
      batch_size: ???
      tgt_lang: de
      src_lang: hsb
      device: 0
      column_key: tgt_text
  save_translation:
    deps: [fwd_translation]
    transform:
      _target_: src.pipelines.data.WriteToArrow
      schema:
        _target_: pyarrow.schema
        _args_:
          -
            - _target_: pyarrow.field
              _args_:
                - ${pipeline.fwd_translation.transform.tgt_lang}_translation
                - _target_: pyarrow.string
      buffer_size: 1024
      path: fwd_translation.arrow
  open_translation:
    deps: [save_translation]
    transform:
      _target_: src.pipelines.data.OpenArrow
  split_into_words:
    deps: [open_translation]
    transform:
      _target_: src.pipelines.word_splitting.WordSplitTransform
      sent_column_key: ${pipeline.fwd_translation.transform.tgt_lang}_translation
      out_key: words
      word_splitter:
        _target_: src.pipelines.word_splitting.NLTKSplitter
  ner:
    deps: [split_into_words]
    transform:
      _target_:  src.pipelines.ner.NERTransform
      model_path: ${ner_model}
      device: 0
      batch_size: 512
      column_key: ${pipeline.split_into_words.transform.out_key}
      wordwise: true
      filter_punctuation: false
  save_src_entities:
    deps: [ner]
    transform:
      _target_: src.pipelines.data.WriteToArrow
      schema: ${schemas.entities_with_words}
      buffer_size: 1024
      path: src_entities.arrow
  open_src_entities_and_words:
    deps: [save_src_entities]
    transform:
      _target_: src.pipelines.data.OpenArrow
  back_translation:
    deps: [open_src_entities_and_words]
    transform:
      _target_: src.pipelines.easy_project.translation.EasyProjectBackTranslationTransform
      model_path: ychenNLP/nllb-200-3.3B-easyproject
      batch_size: 32
      device: 0
      src_lang: ${pipeline.fwd_translation.transform.tgt_lang}
      tgt_lang: ${pipeline.fwd_translation.transform.src_lang}
      src_lang_code: ${pipeline.fwd_translation.transform.tgt_lang_code}
      tgt_lang_code: ${pipeline.fwd_translation.transform.src_lang_code}
      src_words_key: words
      src_entities_key: entities
      word_splitter:
        _target_: src.pipelines.word_splitting.WikiannSplitter
      sim_threshold: 0.5
      out_entities_key: entities
      out_words_key: words
  save_entities:
    deps: [back_translation]
    transform:
      _target_: src.pipelines.data.WriteToArrow
      schema: ${schemas.entities_with_words}
      buffer_size: 1024
      path: tgt_entities.arrow
  open_entities:
    deps: [save_entities]
    transform:
      _target_: src.pipelines.data.OpenArrow
  merge_orig_and_entities:
    deps: [open_entities, open_orig]
    transform:
      _target_: src.pipelines.transforms_base.MergeTransform
  word_align:
    deps: [merge_orig_and_entities]
    transform:
      _target_: src.pipelines.align.word_aligners.WordAlignTransform
      input_orig_words_key: tokens
      input_trans_words_key: words
      batch_size: 512
      word_aligner: ${word_aligner}
  projection:
    deps: [word_align]
    transform:
      _target_: src.pipelines.align.projection.AlignedEntityProjectionTransform
      input_orig_words_key: tokens
      input_trans_words_key: words
      length_ratio_threshold: 0.8
  save_generated_ds:
    deps: [projection]
    transform:
      _target_: src.pipelines.data.WriteGeneratedDataset
      label2id_path: ${pipeline.open_orig.transform.label2id_save_path}
      out_path: generated_ds
  open_gen:
    deps: [save_generated_ds]
    transform:
      _target_: src.pipelines.data.OpenArrow
  evaluate:
    deps: [open_orig, open_gen]
    transform:
      _target_: src.pipelines.eval.EvaluateByCompareTransform
      log_to_mlflow: ${log_to_mlflow}

input_args:
  open_orig: ???

ner_model: julian-schelb/roberta-ner-multilingual

mlflow_tags:
  task: pipeline_eval
  pipeline_type: align_tgt
  eval_type: compare_to_original

mlflow_artifacts_paths:
  gen_ds: ${pipeline.save_generated_ds.transform.out_path}
